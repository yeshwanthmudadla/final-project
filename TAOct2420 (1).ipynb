{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8_lMZEvdLLc_",
    "outputId": "53074d5f-1ee6-4b59-f26d-da36ffa96151"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample extracted images: ['ISIC_0024306.jpg', 'ISIC_0024307.jpg', 'ISIC_0024308.jpg', 'ISIC_0024309.jpg', 'ISIC_0024310.jpg']\n",
      "Sample extracted segmentations: ['HAM10000_segmentations_lesion_tschandl', '__MACOSX']\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import zipfile\n",
    "\n",
    "# Correct directory paths\n",
    "base_dir = \"C:/Users/yeshwanth/Downloads/project yy/dataverse_files\"\n",
    "images_dir = os.path.join(base_dir, \"images\")\n",
    "segmentations_dir = os.path.join(base_dir, \"segmentations\")\n",
    "\n",
    "# Make directories\n",
    "os.makedirs(images_dir, exist_ok=True)\n",
    "os.makedirs(segmentations_dir, exist_ok=True)\n",
    "\n",
    "# Function to extract zip files\n",
    "def extract_zip(zip_path, extract_to):\n",
    "    with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
    "        zip_ref.extractall(extract_to)\n",
    "\n",
    "# Extract image zip files\n",
    "extract_zip(\"C:/Users/yeshwanth/Downloads/project yy/dataverse_files/HAM10000_images_part_1.zip\", images_dir)\n",
    "extract_zip(\"C:/Users/yeshwanth/Downloads/project yy/dataverse_files/HAM10000_images_part_2.zip\", images_dir)\n",
    "\n",
    "# Extract segmentation zip file\n",
    "extract_zip(\"C:/Users/yeshwanth/Downloads/project yy/dataverse_files/HAM10000_segmentations_lesion_tschandl.zip\", segmentations_dir)\n",
    "\n",
    "# Verify extraction by listing sample files\n",
    "print(\"Sample extracted images:\", os.listdir(images_dir)[:5])\n",
    "print(\"Sample extracted segmentations:\", os.listdir(segmentations_dir)[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0UAmY9HIJfoB",
    "outputId": "4b9d8ddd-4589-4b1f-e5db-dc9c2f683846"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final list of files in images folder: ['ISIC_0024306.jpg', 'ISIC_0024307.jpg', 'ISIC_0024308.jpg', 'ISIC_0024309.jpg', 'ISIC_0024310.jpg']\n",
      "Final list of files in segmentations folder: ['ISIC_0024306.jpg', 'ISIC_0024307.jpg', 'ISIC_0024308.jpg', 'ISIC_0024309.jpg', 'ISIC_0024310.jpg']\n"
     ]
    }
   ],
   "source": [
    "# Clean Up __MACOSX Files if Present\n",
    "import shutil\n",
    "\n",
    "# Remove unnecessary __MACOSX directory if it exists\n",
    "macosx_dir = 'C:/Users/yeshwanth/Downloads/project yy/dataverse_files/data/segmentations/__MACOSX'\n",
    "if os.path.exists(macosx_dir):\n",
    "    shutil.rmtree(macosx_dir)\n",
    "    print(\"Removed __MACOSX directory from segmentations folder.\")\n",
    "\n",
    "# Confirm cleaned directories\n",
    "print(\"Final list of files in images folder:\", os.listdir(images_dir)[:5])\n",
    "print(\"Final list of files in segmentations folder:\", os.listdir(images_dir)[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 907
    },
    "id": "x8L4_cSsM2TB",
    "outputId": "7cfb78cb-7cbf-4287-d18e-ff4eba603ef9"
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'cv2'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_17972\\1925099963.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Import necessary libraries for image and mask visualization\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mglob\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mglob\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'cv2'"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries for image and mask visualization\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from glob import glob\n",
    "\n",
    "# Define directories for images and segmentation masks\n",
    "image_dir = os.path.join(base_dir, \"images\")\n",
    "segmentation_dir = 'D:/Dataset/yashwant/data/segmentations/HAM10000_segmentations_lesion_tschandl'\n",
    "\n",
    "# Select a few sample images and corresponding masks\n",
    "sample_image_files = os.listdir(image_dir)[:5]\n",
    "sample_images = [os.path.join(image_dir, img) for img in sample_image_files]\n",
    "\n",
    "# For each image, find the corresponding segmentation mask (assuming they have the same file name)\n",
    "plt.figure(figsize=(15, 10))\n",
    "for i, image_path in enumerate(sample_images):\n",
    "    # Load the image\n",
    "    image = cv2.imread(image_path)\n",
    "    image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)  # Convert to RGB for display\n",
    "\n",
    "    # Load the corresponding mask (assumes masks are named identically to images)\n",
    "    mask_name = os.path.basename(image_path).replace('.jpg', '_segmentation.png')\n",
    "    mask_path = os.path.join(segmentation_dir, mask_name)\n",
    "\n",
    "    # Check if the mask file exists\n",
    "    if os.path.exists(mask_path):\n",
    "        mask = cv2.imread(mask_path, cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "        # Plot image and mask side by side\n",
    "        plt.subplot(5, 2, i * 2 + 1)\n",
    "        plt.imshow(image_rgb)\n",
    "        plt.title(\"Image\")\n",
    "        plt.axis('off')\n",
    "\n",
    "        plt.subplot(5, 2, i * 2 + 2)\n",
    "        plt.imshow(mask, cmap='gray')\n",
    "        plt.title(\"Segmentation Mask\")\n",
    "        plt.axis('off')\n",
    "    else:\n",
    "        print(f\"Mask for {image_path} not found.\")\n",
    "\n",
    "plt.suptitle(\"Sample Images with Corresponding Segmentation Masks\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "PzwdscmcOxFx",
    "outputId": "667b2876-3752-47d3-8305-be825bd06760"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lesion_id</th>\n",
       "      <th>image_id</th>\n",
       "      <th>dx</th>\n",
       "      <th>dx_type</th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>localization</th>\n",
       "      <th>dataset</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>HAM_0000118</td>\n",
       "      <td>ISIC_0027419</td>\n",
       "      <td>bkl</td>\n",
       "      <td>histo</td>\n",
       "      <td>80.0</td>\n",
       "      <td>male</td>\n",
       "      <td>scalp</td>\n",
       "      <td>vidir_modern</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>HAM_0000118</td>\n",
       "      <td>ISIC_0025030</td>\n",
       "      <td>bkl</td>\n",
       "      <td>histo</td>\n",
       "      <td>80.0</td>\n",
       "      <td>male</td>\n",
       "      <td>scalp</td>\n",
       "      <td>vidir_modern</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>HAM_0002730</td>\n",
       "      <td>ISIC_0026769</td>\n",
       "      <td>bkl</td>\n",
       "      <td>histo</td>\n",
       "      <td>80.0</td>\n",
       "      <td>male</td>\n",
       "      <td>scalp</td>\n",
       "      <td>vidir_modern</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>HAM_0002730</td>\n",
       "      <td>ISIC_0025661</td>\n",
       "      <td>bkl</td>\n",
       "      <td>histo</td>\n",
       "      <td>80.0</td>\n",
       "      <td>male</td>\n",
       "      <td>scalp</td>\n",
       "      <td>vidir_modern</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>HAM_0001466</td>\n",
       "      <td>ISIC_0031633</td>\n",
       "      <td>bkl</td>\n",
       "      <td>histo</td>\n",
       "      <td>75.0</td>\n",
       "      <td>male</td>\n",
       "      <td>ear</td>\n",
       "      <td>vidir_modern</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     lesion_id      image_id   dx dx_type   age   sex localization  \\\n",
       "0  HAM_0000118  ISIC_0027419  bkl   histo  80.0  male        scalp   \n",
       "1  HAM_0000118  ISIC_0025030  bkl   histo  80.0  male        scalp   \n",
       "2  HAM_0002730  ISIC_0026769  bkl   histo  80.0  male        scalp   \n",
       "3  HAM_0002730  ISIC_0025661  bkl   histo  80.0  male        scalp   \n",
       "4  HAM_0001466  ISIC_0031633  bkl   histo  75.0  male          ear   \n",
       "\n",
       "        dataset  \n",
       "0  vidir_modern  \n",
       "1  vidir_modern  \n",
       "2  vidir_modern  \n",
       "3  vidir_modern  \n",
       "4  vidir_modern  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the metadata file\n",
    "metadata = pd.read_csv('C:/Users/yeshwanth/Downloads/project yy/dataverse_files/HAM10000_metadata')\n",
    "\n",
    "# Display the first few rows of the metadata\n",
    "metadata_head = metadata.head()\n",
    "metadata_head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "KWe1BMBHevKK",
    "outputId": "3f65dd77-c3f5-42e8-b0cb-abcbe52ff665"
   },
   "outputs": [],
   "source": [
    "# Check the overall structure of the DataFrame\n",
    "metadata.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 335
    },
    "id": "NFTih9LhZWGS",
    "outputId": "cae1a876-6924-4e77-b053-3ca4238f231b"
   },
   "outputs": [],
   "source": [
    "# Display missing values\n",
    "missing_values = metadata.isnull().sum()\n",
    "missing_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Tl3Ps_N8fD7R",
    "outputId": "b0acf821-a64d-4902-ee07-dd03ba676f1a"
   },
   "outputs": [],
   "source": [
    "# Fill missing age values with the median\n",
    "metadata['age'] = metadata['age'].fillna(metadata['age'].median())\n",
    "\n",
    "# Confirm that missing values are handled\n",
    "print(\"\\nAfter Imputation:\")\n",
    "print(metadata.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5rL4z4YxZNbX",
    "outputId": "c33d29fe-3479-4b1b-991b-bd76d84c7ce6"
   },
   "outputs": [],
   "source": [
    "# Summary for numeric columns\n",
    "print(\"\\nSummary of Numeric Columns:\")\n",
    "print(metadata.describe(include=[float]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "VKeqfw69g5Kl",
    "outputId": "4d8b9d6d-64cd-4954-934e-cbbea0e166a9"
   },
   "outputs": [],
   "source": [
    "# Summary for non-numeric columns\n",
    "print(\"\\nSummary of Non-Numeric Columns:\")\n",
    "print(metadata.describe(include=[object]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "S1oZaG7dg8ov",
    "outputId": "f6a475bd-5387-45cb-f289-d26a004c5002"
   },
   "outputs": [],
   "source": [
    "# Check unique values in categorical columns\n",
    "print(\"\\nUnique Values in Categorical Columns:\")\n",
    "for col in metadata.select_dtypes(include=[object]).columns:\n",
    "    print(f\"{col}: {metadata[col].nunique()} unique values\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 675
    },
    "id": "sKi0lyhuaiwY",
    "outputId": "55e84712-5ff2-46f7-a230-a8726ef57a24"
   },
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "# Lesion Type Distribution as a Pie Chart\n",
    "plt.figure(figsize=(8, 8))\n",
    "metadata['dx'].value_counts().plot(kind='pie', autopct='%1.1f%%', startangle=140)\n",
    "plt.title(\"Proportion of Lesion Types\")\n",
    "plt.ylabel(\"\")  # Remove the y-axis label for a cleaner look\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 521
    },
    "id": "RmcI6FMfamPs",
    "outputId": "9576c3a3-e850-4be6-f235-1ce55f29edd7"
   },
   "outputs": [],
   "source": [
    "# Gender Distribution as a Donut Chart\n",
    "gender_counts = metadata['sex'].value_counts()\n",
    "plt.figure(figsize=(6, 6))\n",
    "plt.pie(gender_counts, labels=gender_counts.index, autopct='%1.1f%%', startangle=90, wedgeprops=dict(width=0.3))\n",
    "plt.title(\"Gender Distribution of Patients\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 718
    },
    "id": "ZwLWW7sFaq5b",
    "outputId": "9d7ada57-3ca2-459b-977d-fff83369d461"
   },
   "outputs": [],
   "source": [
    "# Localization Distribution of Lesions as a Horizontal Bar Chart with Percentages\n",
    "localization_counts = metadata['localization'].value_counts(normalize=True) * 100\n",
    "plt.figure(figsize=(10, 8))\n",
    "localization_counts.sort_values().plot(kind='barh')\n",
    "plt.title(\"Localization of Lesions by Percentage\")\n",
    "plt.xlabel(\"Percentage\")\n",
    "plt.ylabel(\"Body Part\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 586
    },
    "id": "kna2ezf-av3u",
    "outputId": "707db21d-9504-49c0-f820-1c41b365e2b4"
   },
   "outputs": [],
   "source": [
    "# Age Distribution across Lesion Types as a Violin Plot\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.violinplot(data=metadata, x='dx', y='age')\n",
    "plt.title(\"Age Distribution by Lesion Type\")\n",
    "plt.xlabel(\"Lesion Type\")\n",
    "plt.ylabel(\"Age\")\n",
    "plt.xticks(rotation=45)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 675
    },
    "id": "Mj_yWNGQbGgA",
    "outputId": "34b810f9-3437-41cd-d8e2-348b2e273bc8"
   },
   "outputs": [],
   "source": [
    "# Diagnosis Type Proportion (Pie chart to reflect diagnostic methods used)\n",
    "plt.figure(figsize=(8, 8))\n",
    "metadata['dx_type'].value_counts().plot(kind='pie', autopct='%1.1f%%', startangle=90, colors=['#99ff99', '#ffcc99', '#ff6666'])\n",
    "plt.title(\"Proportion of Diagnostic Methods\")\n",
    "plt.ylabel(\"\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 564
    },
    "id": "jTJ-a_d9csxP",
    "outputId": "d8b0102e-feb2-4844-ed90-af750a0e18e7"
   },
   "outputs": [],
   "source": [
    "# Replace age = 0 with the median age\n",
    "median_age = metadata['age'].median()\n",
    "metadata['age'] = metadata['age'].replace(0, median_age)\n",
    "\n",
    "# The distribution of age\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.histplot(metadata['age'], bins=20, kde=True)\n",
    "plt.title(\"Age Distribution After Handling Missing Values\")\n",
    "plt.xlabel(\"Age\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "EmlruxyGjXs9",
    "outputId": "ab866cd3-e20d-4b10-c7ef-de9641d9e82f"
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Encode categorical columns\n",
    "categorical_cols = ['dx', 'dx_type', 'sex', 'localization']\n",
    "label_encoders = {}\n",
    "\n",
    "for col in categorical_cols:\n",
    "    le = LabelEncoder()\n",
    "    metadata[col] = le.fit_transform(metadata[col])\n",
    "    label_encoders[col] = le\n",
    "\n",
    "# Check the first few rows to verify encoding\n",
    "print(metadata.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-5y3HwahkFJ2",
    "outputId": "91785d6a-5ee0-4cc0-f7a9-416c9f18cc9d"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Define features and labels\n",
    "X = metadata[['dx', 'dx_type', 'age', 'sex', 'localization']]  # Metadata features\n",
    "y = metadata['dx']  # Labels (encoded diagnosis)\n",
    "\n",
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y, random_state=42)\n",
    "\n",
    "# Verify the split\n",
    "print(f\"Training set size: {X_train.shape[0]}, Testing set size: {X_test.shape[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nihGHhLMk4kM",
    "outputId": "33498e88-9431-4d02-d88c-393a7bf0d094"
   },
   "outputs": [],
   "source": [
    "# Check class distribution in training and testing sets\n",
    "print(\"Training Set Class Distribution:\")\n",
    "print(y_train.value_counts(normalize=True))\n",
    "\n",
    "print(\"\\nTesting Set Class Distribution:\")\n",
    "print(y_test.value_counts(normalize=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LlmHdctckeM2",
    "outputId": "015f6cb3-1cd2-4f2e-8aa2-b123644921bd"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "import os\n",
    "\n",
    "# Ensure image paths are correctly formatted\n",
    "metadata['image_id'] = metadata['image_id'].apply(lambda x: f\"{x}.jpg\" if not x.endswith('.jpg') else x)\n",
    "\n",
    "# Define the image directory\n",
    "image_dir = os.path.join(base_dir, \"images\")\n",
    "\n",
    "# Ensure the dx column contains strings\n",
    "metadata['dx'] = metadata['dx'].astype(str)\n",
    "\n",
    "# Define the image generator\n",
    "datagen = ImageDataGenerator(\n",
    "    rescale=1./255,           # Normalize pixel values to [0, 1]\n",
    "    rotation_range=20,        # Randomly rotate images\n",
    "    width_shift_range=0.2,    # Randomly shift images horizontally\n",
    "    height_shift_range=0.2,   # Randomly shift images vertically\n",
    "    zoom_range=0.2,           # Randomly zoom images\n",
    "    horizontal_flip=True,     # Randomly flip images horizontally\n",
    "    validation_split=0.2      # Reserve 20% of data for validation\n",
    ")\n",
    "\n",
    "# Training generator\n",
    "train_generator = datagen.flow_from_dataframe(\n",
    "    dataframe=metadata,\n",
    "    directory=image_dir,\n",
    "    x_col='image_id',\n",
    "    y_col='dx',\n",
    "    target_size=(128, 128),    # Resize images to 128x128 pixels\n",
    "    batch_size=32,             # Batch size\n",
    "    class_mode='categorical',  # Multi-class classification\n",
    "    subset='training',         # Use the training subset\n",
    "    shuffle=True               # Shuffle data\n",
    ")\n",
    "\n",
    "# Validation generator\n",
    "val_generator = datagen.flow_from_dataframe(\n",
    "    dataframe=metadata,\n",
    "    directory=image_dir,\n",
    "    x_col='image_id',\n",
    "    y_col='dx',\n",
    "    target_size=(128, 128),\n",
    "    batch_size=32,\n",
    "    class_mode='categorical',\n",
    "    subset='validation'\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 476
    },
    "id": "jtSe78l9khNx",
    "outputId": "8bb2dac9-680e-4134-ba74-3739923c93cb"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "\n",
    "# Define CNN model\n",
    "model = Sequential([\n",
    "    # First convolutional block\n",
    "    Input(shape=(128, 128, 3)),\n",
    "    Conv2D(32, (3, 3), activation='relu', input_shape=(128, 128, 3)),\n",
    "    MaxPooling2D((2, 2)),\n",
    "\n",
    "    # Second convolutional block\n",
    "    Conv2D(64, (3, 3), activation='relu'),\n",
    "    MaxPooling2D((2, 2)),\n",
    "\n",
    "    # Third convolutional block\n",
    "    Conv2D(128, (3, 3), activation='relu'),\n",
    "    MaxPooling2D((2, 2)),\n",
    "\n",
    "    # Flatten and fully connected layers\n",
    "    Flatten(),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dropout(0.5),  # Dropout for regularization\n",
    "    Dense(7, activation='softmax')  # 7 classes for skin lesion types\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Print model summary\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JQZ1md8JkiZr",
    "outputId": "896a06e1-1d28-4baf-ce48-9c36bd059ca7"
   },
   "outputs": [],
   "source": [
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "import numpy as np\n",
    "\n",
    "# Compute class weights for imbalanced data\n",
    "class_weights = compute_class_weight(\n",
    "    class_weight='balanced',\n",
    "    classes=np.unique(metadata['dx']),\n",
    "    y=metadata['dx']\n",
    ")\n",
    "class_weights_dict = dict(enumerate(class_weights))\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(\n",
    "    train_generator,\n",
    "    validation_data=val_generator,\n",
    "    epochs=10,                    # Number of epochs\n",
    "    steps_per_epoch=len(train_generator),\n",
    "    validation_steps=len(val_generator),\n",
    "    class_weight=class_weights_dict  # Add class weights to balance training\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "qk76DD3mklo-"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_17972\\264013820.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;31m# Evaluate model performance\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m \u001b[0mtest_loss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_acc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mval_generator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"Test Accuracy: {test_acc:.2f}\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Evaluate model performance\n",
    "test_loss, test_acc = model.evaluate(val_generator)\n",
    "print(f\"Test Accuracy: {test_acc:.2f}\")\n",
    "\n",
    "# Predict on the validation data\n",
    "y_pred = model.predict(val_generator)\n",
    "y_pred_classes = np.argmax(y_pred, axis=1)\n",
    "y_true = val_generator.classes\n",
    "\n",
    "# Generate classification report\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_true, y_pred_classes))\n",
    "\n",
    "# Confusion matrix\n",
    "conf_matrix = confusion_matrix(y_true, y_pred_classes)\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues',\n",
    "            xticklabels=val_generator.class_indices.keys(),\n",
    "            yticklabels=val_generator.class_indices.keys())\n",
    "plt.title(\"Confusion Matrix\")\n",
    "plt.xlabel(\"Predicted Labels\")\n",
    "plt.ylabel(\"True Labels\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8dHCHyg0nbzS"
   },
   "outputs": [],
   "source": [
    "# Plot training and validation accuracy\n",
    "plt.plot(history.history['accuracy'], label='Training Accuracy')\n",
    "plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
    "plt.title('Training and Validation Accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# Plot training and validation loss\n",
    "plt.plot(history.history['loss'], label='Training Loss')\n",
    "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "D_J23p3zqyOB"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications import VGG16\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Dense, Flatten, Dropout\n",
    "\n",
    "# Load the pre-trained VGG16 model without the top layer\n",
    "base_model = VGG16(weights='imagenet', include_top=False, input_shape=(128, 128, 3))\n",
    "\n",
    "# Freeze the base model layers\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "# Add custom layers on top\n",
    "x = Flatten()(base_model.output)\n",
    "x = Dense(128, activation='relu')(x)\n",
    "x = Dropout(0.5)(x)\n",
    "output = Dense(7, activation='softmax')(x)  # 7 classes\n",
    "\n",
    "# Create the model\n",
    "model_vgg16 = Model(inputs=base_model.input, outputs=output)\n",
    "\n",
    "# Compile the model\n",
    "model_vgg16.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Summary\n",
    "model_vgg16.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nAGcvVdMro0J"
   },
   "outputs": [],
   "source": [
    "# Train the model\n",
    "history_vgg16 = model_vgg16.fit(\n",
    "    train_generator,\n",
    "    validation_data=val_generator,\n",
    "    epochs=10,\n",
    "    steps_per_epoch=len(train_generator),\n",
    "    validation_steps=len(val_generator),\n",
    "    class_weight=class_weights_dict\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Xr4c9LscsEsv"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications import ResNet50\n",
    "\n",
    "# Load the pre-trained ResNet50 model without the top layer\n",
    "base_model = ResNet50(weights='imagenet', include_top=False, input_shape=(128, 128, 3))\n",
    "\n",
    "# Freeze the base model layers\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "# Add custom layers on top\n",
    "x = Flatten()(base_model.output)\n",
    "x = Dense(128, activation='relu')(x)\n",
    "x = Dropout(0.5)(x)\n",
    "output = Dense(7, activation='softmax')(x)  # 7 classes\n",
    "\n",
    "# Create the model\n",
    "model_resnet50 = Model(inputs=base_model.input, outputs=output)\n",
    "\n",
    "# Compile the model\n",
    "model_resnet50.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Summary\n",
    "model_resnet50.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "TGcXCqGQsKfx"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model_resnet50' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_17972\\4274765218.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Train the model\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m history_resnet50 = model_resnet50.fit(\n\u001b[0m\u001b[0;32m      3\u001b[0m     \u001b[0mtrain_generator\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0mvalidation_data\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mval_generator\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'model_resnet50' is not defined"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "history_resnet50 = model_resnet50.fit(\n",
    "    train_generator,\n",
    "    validation_data=val_generator,\n",
    "    epochs=10,\n",
    "    steps_per_epoch=len(train_generator),\n",
    "    validation_steps=len(val_generator),\n",
    "    class_weight=class_weights_dict\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
